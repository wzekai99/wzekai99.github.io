<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="bJifYeU5_78wrxhSyC5O7CWMNJIJMgxFyGeVFxrzJ-s">
<meta name="msvalidate.01" content="0F47E8F5E819CF25475BA844139C6069">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Zekai  Wang</title>
    <meta name="author" content="Zekai  Wang">
    <meta name="description" content="(* indicates equal contribution)">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%A1&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://zekai.site/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Zekai </span>Wang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description">(* indicates equal contribution)</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2024</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AAAI’24</abbr></div>

        <!-- Entry bib key -->
        <div id="wang2024drf" class="col-sm-8">
        <!-- Title --><div class="title">DRF: Improving Certified Robustness via Distributional Robustness Framework</div>
<!-- Author -->
        <div class="author">
        

        <strong><u>Zekai Wang</u></strong>, Zhengyu Zhou, and <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2024
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Randomized smoothing (RS) provides state-of-the-art (SOTA) certified robustness against L2-perturbations for large neural networks. Among studies in this field, methods based on adversarial training (AT) achieve remarkably robust performance by applying adversarial examples to construct the smoothed classifier. These AT-based RS methods typically seek a pointwise adversary that generates the worst-case adversarial examples by perturbing each input independently. However, there are unexplored benefits to considering such adversarial robustness across the entire data distribution. To this end, we provide a novel framework called DRF, which connects AT-based RS methods with distributional robustness (DR), and show that these methods are special cases of their counterparts in our framework. Due to the advantages conferred by DR, our framework can control the trade-off between the clean accuracy and certified robustness of smoothed classifiers to a significant extent. Our experiments demonstrate that DRF can substantially improve the certified L2-robustness of AT-based RS.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2024drf</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DRF: Improving Certified Robustness via Distributional Robustness Framework}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Zekai and Zhou, Zhengyu and Liu, Weiwei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">JMLR</abbr></div>

        <!-- Entry bib key -->
        <div id="wang2023rvcl" class="col-sm-8">
        <!-- Title --><div class="title"><a href="https://jmlr.org/papers/volume24/23-0668/23-0668.pdf" rel="external nofollow noopener" target="_blank">RVCL: Evaluating the Robustness of Contrastive Learning via Verification</a></div>
<!-- Author -->
        <div class="author">
        

        <strong><u>Zekai Wang</u></strong>, and <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Machine Learning Research</em>, 2023
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="http://jmlr.org/papers/v24/23-0668.html" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://github.com/wzekai99/RVCL-JMLR" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Contrastive adversarial training has successfully improved the robustness of contrastive learning (CL). However, the robustness metric in these methods depends on attack algorithms, image labels, and downstream tasks, introducing reliability concerns. To address these issues, this paper proposes a novel Robustness Verification framework for Contrastive Learning (RVCL). Specifically, we define the verification problem of CL from deterministic and probabilistic perspectives, then provide several effective metrics to evaluate the robustness of CL encoder. Furthermore, we use extreme value theory to reveal the relationship between the robust radius of the CL encoder and that of the supervised downstream task. Extensive experiments on various benchmark models and datasets validate theoretical findings, and further demonstrate RVCL’s capability to evaluate the robustness of both CL encoders and images.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">wang2023rvcl</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{RVCL: Evaluating the Robustness of Contrastive Learning via Verification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Zekai and Liu, Weiwei}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{396}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--43}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML’23</abbr></div>

        <!-- Entry bib key -->
        <div id="wang2023better" class="col-sm-8">
        <!-- Title --><div class="title"><a href="https://proceedings.mlr.press/v202/wang23ad/wang23ad.pdf" rel="external nofollow noopener" target="_blank">Better Diffusion Models Further Improve Adversarial Training</a></div>
<!-- Author -->
        <div class="author">
        

        <strong><u>Zekai Wang</u></strong>*, <a href="https://p2333.github.io" rel="external nofollow noopener" target="_blank">Tianyu Pang</a>*, <a href="https://duchao0726.github.io" rel="external nofollow noopener" target="_blank">Chao Du</a>, <a href="https://linmin.me" rel="external nofollow noopener" target="_blank">Min Lin</a>, <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>, and <a href="https://yanshuicheng.info" rel="external nofollow noopener" target="_blank">Shuicheng Yan</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Machine Learning</em>, 2023
        </div>
        <div class="periodical">
          
        </div>
<span style="color: var(--global-theme-color); font-weight: bolder">New state-of-the-art performance on the <a href="https://robustbench.github.io" rel="external nofollow noopener" target="_blank">RobustBench leaderboard</a></span><!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a href="http://arxiv.org/abs/2302.04638" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://proceedings.mlr.press/v202/wang23ad.html" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://github.com/wzekai99/DM-Improves-AT" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
            <a href="https://icml.cc/virtual/2023/poster/24423" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>It has been recognized that the data generated by the denoising diffusion probabilistic model (DDPM) improves adversarial training. After two years of rapid development in diffusion models, a question naturally arises: can better diffusion models further improve adversarial training? This paper gives an affirmative answer by employing the most recent diffusion model which has higher efficiency (∼20 sampling steps) and image quality (lower FID score) compared with DDPM. Our adversarially trained models achieve state-of-the-art performance on RobustBench using only generated data (no external datasets). Under the L∞-norm threat model with ε=8/255, our models achieve 70.69% and 42.67% robust accuracy on CIFAR-10 and CIFAR-100, respectively, i.e. improving upon previous state-of-the-art models by +4.58% and +8.03%. Under the L2-norm threat model with ε=128/255, our models achieve 84.86% on CIFAR-10 (+4.44%). These results also beat previous works that use external data. We also provide compelling results on the SVHN and TinyImageNet datasets.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2023better</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Better Diffusion Models Further Improve Adversarial Training}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Zekai and Pang, Tianyu and Du, Chao and Lin, Min and Liu, Weiwei and Yan, Shuicheng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{202}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{36246--36263}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">TKDE</abbr></div>

        <!-- Entry bib key -->
        <div id="mao2023task" class="col-sm-8">
        <!-- Title --><div class="title">Task Variance Regularized Multi-Task Learning</div>
<!-- Author -->
        <div class="author">
        

        Yuren Mao, <strong><u>Zekai Wang</u></strong>, <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>, Xuemin Lin, and Wenbin Hu</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>IEEE Transactions on Knowledge and Data Engineering</em>, 2023
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/9893398" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Multi-task Learning (MTL), which involves the simultaneous learning of multiple tasks, can achieve better performance than learning each task independently. It has achieved great success in various applications, ranging from Computer Vision (CV) to Natural Language Processing (NLP). In MTL, the losses of the including tasks are jointly optimized. However, it is common for these tasks to be competing. When the tasks are competing, minimizing the losses of some tasks increases the losses of others, which accordingly increases the task variance (variance between the task-specific loss); furthermore, it induces under-fitting in some tasks and over-fitting in others, which degenerates the generalization performance of an MTL model. To address this issue, it is necessary to control the task variance; thus, task variance regularization is a natural choice. While intuitive, task variance regularization remains unexplored in MTL. Accordingly, to fill this gap, we study the generalization error bound of MTL through the lens of task variance and propose the task variance matters the generalization performance of MTL. Furthermore, this paper investigates how the task variance might be effectively regularized, and consequently proposes a multi-task learning method based on adversarial multi-armed bandit. The proposed method, dubbed BanditMTL, regularizes the task variance by means of a mirror gradient ascent-descent algorithm. Adopting BanditMTL both in CV and NLP applications is found to achieve state-of-the-art performance. The results of extensive experiments back up our theoretical analysis and validate the superiority of our proposals.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">mao2023task</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Task Variance Regularized Multi-Task Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mao, Yuren and Wang, Zekai and Liu, Weiwei and Lin, Xuemin and Hu, Wenbin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Knowledge and Data Engineering}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8615-8629}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ICML’22</abbr><abbr class="badge badge-light">Oral</abbr>
</div>

        <!-- Entry bib key -->
        <div id="wang2022robustness" class="col-sm-8">
        <!-- Title --><div class="title"><a href="https://proceedings.mlr.press/v162/wang22q/wang22q.pdf" rel="external nofollow noopener" target="_blank">Robustness Verification for Contrastive Learning</a></div>
<!-- Author -->
        <div class="author">
        

        <strong><u>Zekai Wang</u></strong>, and <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Machine Learning</em>, 2022
        </div>
        <div class="periodical">
          
        </div>
<span style="color: var(--global-theme-color); font-weight: bolder">Long Presentation (top 2%)</span><!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://proceedings.mlr.press/v162/wang22q.html" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://icml.cc/virtual/2022/oral/16762" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a>
            <a href="https://github.com/wzekai99/RVCL" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
            <a href="https://icml.cc/virtual/2022/poster/16761" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Contrastive adversarial training has successfully improved the robustness of contrastive learning (CL). However, the robustness metric used in these methods is linked to attack algorithms, image labels and downstream tasks, all of which may affect the consistency and reliability of robustness metric for CL. To address these problems, this paper proposes a novel Robustness Verification framework for Contrastive Learning (RVCL). Furthermore, we use extreme value theory to reveal the relationship between the robust radius of the CL encoder and that of the supervised downstream task. Extensive experimental results on various benchmark models and datasets verify our theoretical findings, and further demonstrate that our proposed RVCL is able to evaluate the robustness of both models and images.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2022robustness</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robustness Verification for Contrastive Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Zekai and Liu, Weiwei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{162}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{22865--22883}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS’22</abbr></div>

        <!-- Entry bib key -->
        <div id="ma2022tradeoff" class="col-sm-8">
        <!-- Title --><div class="title"><a href="https://papers.nips.cc/paper_files/paper/2022/file/a80ebbb4ec9e9b39789318a0a61e2e43-Paper-Conference.pdf" rel="external nofollow noopener" target="_blank">On the Tradeoff Between Robustness and Fairness</a></div>
<!-- Author -->
        <div class="author">
        

        Xinsong Ma, <strong><u>Zekai Wang</u></strong>, and <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Advances in Neural Information Processing Systems</em>, 2022
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://papers.nips.cc/paper_files/paper/2022/hash/a80ebbb4ec9e9b39789318a0a61e2e43-Abstract-Conference.html" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://github.com/wzekai99/FAT" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Interestingly, recent experimental results have identified a robust fairness phenomenon in adversarial training (AT), namely that a robust model well-trained by AT exhibits a remarkable disparity of standard accuracy and robust accuracy among different classes compared with natural training. However, the effect of different perturbation radii in AT on robust fairness has not been studied, and one natural question is raised: does a tradeoff exist between average robustness and robust fairness? Our extensive experimental results provide an affirmative answer to this question: with an increasing perturbation radius, stronger AT will lead to a larger class-wise disparity of robust accuracy. Theoretically, we analyze the class-wise performance of adversarially trained linear models with mixture Gaussian distribution. Our theoretical results support our observations. Moreover, our theory shows that adversarial training easily leads to more serious robust fairness issue than natural training. Motivated by theoretical results, we propose a fairly adversarial training (FAT) method to mitigate the tradeoff between average robustness and robust fairness. Experimental results validate the effectiveness of our proposed method.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ma2022tradeoff</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Tradeoff Between Robustness and Fairness}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ma, Xinsong and Wang, Zekai and Liu, Weiwei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{26230--26241}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ACL’22</abbr><abbr class="badge badge-light">Findings</abbr>
</div>

        <!-- Entry bib key -->
        <div id="mao2022metaweighting" class="col-sm-8">
        <!-- Title --><div class="title"><a href="https://aclanthology.org/2022.findings-acl.271.pdf" rel="external nofollow noopener" target="_blank">MetaWeighting: Learning to Weight Tasks in Multi-Task Learning</a></div>
<!-- Author -->
        <div class="author">
        

        Yuren Mao, <strong><u>Zekai Wang</u></strong>, <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>, Xuemin Lin, and Pengtao Xie</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Findings of the Association for Computational Linguistics</em>, 2022
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://aclanthology.org/2022.findings-acl.271" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://underline.io/lecture/50124-metaweighting-learning-to-weight-tasks-in-multi-task-learning" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Task weighting, which assigns weights on the including tasks during training, significantly matters the performance of Multi-task Learning (MTL); thus, recently, there has been an explosive interest in it. However, existing task weighting methods assign weights only based on the training loss, while ignoring the gap between the training loss and generalization loss. It degenerates MTL’s performance. To address this issue, the present paper proposes a novel task weighting algorithm, which automatically weights the tasks via a learning-to-learn paradigm, referred to as MetaWeighting. Extensive experiments are conducted to validate the superiority of our proposed method in multi-task text classification.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mao2022metaweighting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MetaWeighting: Learning to Weight Tasks in Multi-Task Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mao, Yuren and Wang, Zekai and Liu, Weiwei and Lin, Xuemin and Xie, Pengtao}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3436--3448}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ICML’22</abbr><abbr class="badge badge-light">Workshop</abbr>
</div>

        <!-- Entry bib key -->
        <div id="wang2022rvclworkshop" class="col-sm-8">
        <!-- Title --><div class="title"><a href="http://download.huan-zhang.com/events/wfvml2022/papers/15_CameraReady_RVCL_camera.pdf" rel="external nofollow noopener" target="_blank">Robustness Verification Framework for Self-supervised Contrastive Learning</a></div>
<!-- Author -->
        <div class="author">
        

        <strong><u>Zekai Wang</u></strong>, and <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In ICML Workshop on Formal Verification of Machine Learning (WFVML)</em>, 2022
        </div>
        <div class="periodical">
          
        </div>
<span style="color: var(--global-theme-color); font-weight: bolder">Accepted by ICML’22 main conference</span><!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a href="https://www.ml-verification.com/2022/accepted-papers" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Contrastive adversarial training has successfully improved the robustness of contrastive learning (CL). However, the robustness metric used in these methods is linked to attack algorithms, image labels and downstream tasks, all of which may affect the consistency and reliability of robustness metric for CL. To address these problems, this paper proposes a novel Robustness Verification framework for Contrastive Learning (RVCL). Furthermore, we use extreme value theory to reveal the relationship between the robust radius of the CL encoder and that of the supervised downstream task. Extensive experimental results on various benchmark models and datasets verify our theoretical findings, and further demonstrate that our proposed RVCL is able to evaluate the robustness of both models and images.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge badge-light">MEMS</abbr></div>

        <!-- Entry bib key -->
        <div id="guo2022deep" class="col-sm-8">
        <!-- Title --><div class="title">Deep learning for non-parameterized MEMS structural design</div>
<!-- Author -->
        <div class="author">
        

        Ruiqi Guo, Fanping Sui, Wei Yue, <strong><u>Zekai Wang</u></strong>, Sedat Pala, Kunying Li, Renxiao Xu, and Liwei Lin</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Microsystems &amp; Nanoengineering</em>, 2022
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://www.nature.com/articles/s41378-022-00432-9" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The geometric designs of MEMS devices can profoundly impact their physical properties and eventual performances. However, it is challenging for researchers to rationally consider a large number of possible designs, as it would be very time- and resource-consuming to study all these cases using numerical simulation. In this paper, we report the use of deep learning techniques to accelerate the MEMS design cycle by quickly and accurately predicting the physical properties of numerous design candidates with vastly different geometric features. Design candidates are represented in a nonparameterized, topologically unconstrained form using pixelated black-and-white images. After sufficient training, a deep neural network can quickly calculate the physical properties of interest with good accuracy without using conventional numerical tools such as finite element analysis. As an example, we apply our deep learning approach in the prediction of the modal frequency and quality factor of disk-shaped microscale resonators. With reasonable training, our deep learning neural network becomes a high-speed, high-accuracy calculator: it can identify the flexural mode frequency and the quality factor 4.6 × 103 times and 2.6 × 104 times faster, respectively, than conventional numerical simulation packages, with good accuracies of 98.8 ± 1.6% and 96.8 ± 3.1%, respectively. When simultaneously predicting the frequency and the quality factor, up to ∼96.0% of the total computation time can be saved during the design process. The proposed technique can rapidly screen over thousands of design candidates and promotes experience-free and data-driven MEMS structural designs.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">guo2022deep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep learning for non-parameterized MEMS structural design}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guo, Ruiqi and Sui, Fanping and Yue, Wei and Wang, Zekai and Pala, Sedat and Li, Kunying and Xu, Renxiao and Lin, Liwei}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Microsystems \&amp; Nanoengineering}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{91}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group UK London}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACL’21</abbr></div>

        <!-- Entry bib key -->
        <div id="mao2021banditmtl" class="col-sm-8">
        <!-- Title --><div class="title"><a href="https://aclanthology.org/2021.acl-long.428.pdf" rel="external nofollow noopener" target="_blank">BanditMTL: Bandit-based Multi-task Learning for Text Classification</a></div>
<!-- Author -->
        <div class="author">
        

        Yuren Mao, <strong><u>Zekai Wang</u></strong>, <a href="https://sites.google.com/site/weiweiliuhomepage" rel="external nofollow noopener" target="_blank">Weiwei Liu</a>, Xuemin Lin, and Wenbin Hu</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Annual Meeting of the Association for Computational Linguistics</em>, 2021
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://aclanthology.org/2021.acl-long.428" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
            <a href="https://underline.io/lecture/25856-banditmtl-bandit-based-multi-task-learning-for-text-classification" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Task variance regularization, which can be used to improve the generalization of Multi-task Learning (MTL) models, remains unexplored in multi-task text classification. Accordingly, to fill this gap, this paper investigates how the task might be effectively regularized, and consequently proposes a multi-task learning method based on adversarial multi-armed bandit. The proposed method, named BanditMTL, regularizes the task variance by means of a mirror gradient ascent-descent algorithm. Adopting BanditMTL in the multi-task text classification context is found to achieve state-of-the-art performance. The results of extensive experiments back up our theoretical analysis and validate the superiority of our proposals.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mao2021banditmtl</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BanditMTL: Bandit-based Multi-task Learning for Text Classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mao, Yuren and Wang, Zekai and Liu, Weiwei and Lin, Xuemin and Hu, Wenbin}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Annual Meeting of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5506--5516}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge badge-light">MEMS</abbr></div>

        <!-- Entry bib key -->
        <div id="guo2021accelerating" class="col-sm-8">
        <!-- Title --><div class="title">Accelerating MEMS design process through machine learning from pixelated binary images</div>
<!-- Author -->
        <div class="author">
        

        Ruiqi Guo, Renxiao Xu, <strong><u>Zekai Wang</u></strong>, Fanping Sui, and Liwei Lin</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Micro Electro Mechanical Systems</em>, 2021
        </div>
        <div class="periodical">
          
        </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/document/9375315" class="btn z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper reports the use of machine learning in accelerating the MEMS design process. Candidate designs are represented by pixelated binary 2D images. Instead of common computational tools like FEA, we use trained neural network for quickly obtaining physical properties of interest for each candidate design. Circular disk resonators are used as an example to demonstrate the capability of our method. After sufficient training with 9000 images, the resulting neural network can serve as a high-speed, high-accuracy analyzer: it can identify four vibrational modes of interest and calculate the corresponding frequencies 4000 times faster than commonly used FEA software, with remarkable accuracy  (∼98%).</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">guo2021accelerating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Accelerating MEMS design process through machine learning from pixelated binary images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guo, Ruiqi and Xu, Renxiao and Wang, Zekai and Sui, Fanping and Lin, Liwei}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Micro Electro Mechanical Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{153--156}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>


</div>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Zekai  Wang. Last updated: March 06, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-2W5EM1MVTS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-2W5EM1MVTS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
